{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate data with X of 3 dimensions.\n",
    "n_features = 3\n",
    "n_samples = 10000\n",
    "X = np.random.random((n_samples,n_features))\n",
    "X_input = np.concatenate((np.ones((n_samples,1)),X),axis=1)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-1*x))\n",
    "\n",
    "def convert_to_binary(x):\n",
    "    if(x<=0.5):\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "theta = np.random.normal(size=(n_features+1,1))\n",
    "Y_input = sigmoid(np.dot(X_input,theta)+np.random.normal(size=(n_samples,1)))\n",
    "Y_input = np.apply_along_axis(convert_to_binary, 1, Y_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=False,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(C=50,fit_intercept=False)\n",
    "lr.fit(X_input,Y_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients :  [[ 2.76757941 -1.11739068 -0.13485474 -0.53046064]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients : \", lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients :  [ 2.76837084 -1.11798606 -0.13521582 -0.53088574]\n"
     ]
    }
   ],
   "source": [
    "#Implement Logistic Regression using gradient descent\n",
    "n_iterations=60000\n",
    "alpha=0.5\n",
    "theta_gd = np.random.normal(size=(n_features+1,1))\n",
    "Y_input = Y_input.reshape(-1,1) #to make it compatible with matrix multiplication\n",
    "\n",
    "for iterations in range(n_iterations):\n",
    "    Y_hat = sigmoid(np.dot(X_input,theta_gd)) #Y_hat = (n_samples,1)\n",
    "    grad = 1/(n_samples)*np.dot(X_input.T,(Y_hat-Y_input))\n",
    "    theta_gd = theta_gd - alpha*grad\n",
    "\n",
    "\n",
    "print(\"Coefficients : \",theta_gd.flatten())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
